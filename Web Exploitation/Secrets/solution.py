from urllib.parse import urljoin

import requests
import lxml.html
import re
import slimit.parser
import slimit.ast


def find_flag(base_url):  # TODO: Rewrite this as recursion
    resp = requests.get(base_url)
    doc = lxml.html.fromstring(resp.content)
    hrefs = doc.xpath("//link/@href")
    for href in hrefs:
        subdir_resp = requests.get(urljoin(resp.url, href.split("/")[0] + "/"))
        if 200 <= subdir_resp.status_code <= 299:
            subdir_doc = lxml.html.fromstring(subdir_resp.content)
            subdir_hrefs = subdir_doc.xpath("//link/@href")
            for subdir_href in subdir_hrefs:
                second_subdir_resp = requests.get(urljoin(subdir_resp.url, subdir_href.split("/")[0] + "/"))
                if 200 <= second_subdir_resp.status_code <= 299:
                    second_subdir_doc = lxml.html.fromstring(second_subdir_resp.text)
                    second_subdir_hrefs = second_subdir_doc.xpath("//input[@type='hidden']/@value")
                    for second_subdir_href in second_subdir_hrefs:
                        third_subdir_resp = requests.get(
                            urljoin(second_subdir_resp.url, second_subdir_href.split("/")[0] + "/"))
                        if 200 <= third_subdir_resp.status_code <= 299:
                            third_subdir_doc = lxml.html.fromstring(third_subdir_resp.text)
                            return "".join(third_subdir_doc.xpath("//*[@class='flag']/text()")).strip()


flag = find_flag("http://saturn.picoctf.net:61481/")
print(flag)
